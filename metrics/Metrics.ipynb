{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9b16a06",
   "metadata": {},
   "source": [
    "### Similarity metrics (*content-based filtering*)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12851ff",
   "metadata": {},
   "source": [
    "#### Cosine similarity \n",
    "\n",
    "$$ cosine(x, y) = \\frac{\\sum_i{x_i \\cdot y_i}}{\\sqrt{\\sum_i{x_i^2}} \\cdot {\\sqrt{\\sum_i{y_i^2}}}} $$\n",
    "\n",
    "* Seems like *cosine* is very similar to *Pearson correlation* (\n",
    "$ corr(x, y) = \\frac{E((X - E(X)) \\cdot (Y - E(Y)))}  {\\sqrt{D(X)} \\cdot \\sqrt{D(Y)}} $ )\n",
    "\n",
    "#### Jaccard index\n",
    "$$ Jacc(A, B) = \\frac{|A \\cap B|}{|A \\cup B|} $$\n",
    "* Only for binary item encodings\n",
    "* For instance, can be applied to One-Hot-Encoded item tags \n",
    "\n",
    "#### Euclidean distance\n",
    "$$ dist(x, y) = \\sqrt{\\sum_i{(x_i-y_i)^2}} $$\n",
    "\n",
    "#### Minkowski distance\n",
    "$$ dist(x, y) = (\\sum_i^n{|x_i-y_i|^n}) ^ \\frac{1}{n}  $$\n",
    "\n",
    "#### Pearson/Spearman/Kendall/... correlation\n",
    "* Coefficients can then be used as weights to get the target for vector x:\n",
    "    $$target(x) = weights \\cdot targets $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e858dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\t[0.93451155 0.65743761 0.9961082  0.27446787 0.4783896  0.13702663\n",
      " 0.14188131 0.42261796 0.88377803 0.46889177 0.35044283 0.97407723\n",
      " 0.39320223 0.78466728 0.47554408 0.21141312 0.60334072 0.63639123\n",
      " 0.79672015 0.62417076]\n",
      "y:\t[0.97451155 0.69743761 1.0361082  0.31446787 0.5183896  0.17702663\n",
      " 0.18188131 0.46261796 0.92377803 0.50889177 0.39044283 1.01407723\n",
      " 0.43320223 0.82466728 0.51554408 0.25141312 0.64334072 0.67639123\n",
      " 0.83672015 0.66417076]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate similar vectors\n",
    "\n",
    "x = np.random.uniform(size=20)\n",
    "y = x + np.random.normal(0.04, 0, size=20)\n",
    "\n",
    "print(f'x:\\t{x}')\n",
    "print(f'y:\\t{y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a9154",
   "metadata": {},
   "source": [
    "### Simple implementions of some similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb7e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(x: np.array, y: np.array) -> float:\n",
    "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "def jaccard(x: np.array, y: np.array) -> float:\n",
    "    uni = (x == y).sum()\n",
    "    inter = x.size + y.size - uni\n",
    "    return uni / inter\n",
    "\n",
    "def euclidean(x: np.array, y: np.array) -> float:\n",
    "    return np.linalg.norm(x - y)\n",
    "\n",
    "def minkowski(x: np.array, y: np.array, n: int = 2) -> float:\n",
    "    return np.sum(np.abs(x - y) ** n) ** (1 / n)\n",
    "\n",
    "def pearson(x: np.array, y: np.array) -> float:    \n",
    "    return np.mean(\n",
    "        (x - np.mean(x)) * (y - np.mean(y))\n",
    "    ) / np.sqrt(np.var(x) * np.var(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab9a053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity:\t0.9996641581280302\n",
      "Euclidean similarity:\t0.1788854381999832\n",
      "Minkowski similarity:\t0.1788854381999832\n",
      "Minkowski similarity:\t0.1085767046637963\n",
      "Pearson similarity:\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Cosine similarity:\\t{cosine(x, y)}')\n",
    "print(f'Euclidean similarity:\\t{euclidean(x, y)}')\n",
    "print(f'Minkowski similarity:\\t{minkowski(x, y)}')\n",
    "print(f'Minkowski similarity:\\t{minkowski(x, y, 3)}')\n",
    "print(f'Pearson similarity:\\t{pearson(x, y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d521ead",
   "metadata": {},
   "source": [
    "### Predictive metrics\n",
    "- MAE\n",
    "- RMSE\n",
    "- Classification metrics (Accuracy, Precision, Recall, F1,  ROC-AUC, PR-AUC, ...)\n",
    "- Decision support metrics\n",
    "  1. **Precision@k**\n",
    "        $$ Precision@k = \\frac{\\text{Relevant items in top-k recommendations}}{\\text{All recommended items at k}} = \\frac{TP}{TP + FP}$$\n",
    "  2. **Recall@k ( aka Hitrate@k )**\n",
    "      $$ Recall@k = \\frac{\\text{Relevant items in top-k recommendations}}{\\text{All relevant items}} = \\frac{TP}{TP + FN}$$\n",
    "  3. **F1@k**\n",
    "      $$ F1@k = \\frac{2 \\cdot Precision@k \\cdot Recall@k}{Precision@k + Recall@k} $$\n",
    "- Ranking based metrics\n",
    "  1. **Average Precision**\n",
    "        $$ AP@N =   \\frac{1}{m} \\cdot \\sum_{k=1}^N{relevant(k) \\cdot P(k)} $$\n",
    "      $ relevant(k) \\text{ = 1 if k-th item is relevant else 0} $\n",
    "      \n",
    "      $ m $ - number of items user adds\n",
    "  2. **MAP**\n",
    "  3. **DCG (Discounted cumulative gain)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e285455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_k(real: np.array, preds: np.array, rec_threshold=0.5, k=5):\n",
    "    real = real[(-preds).argsort()]\n",
    "    preds.sort()\n",
    "    \n",
    "    top_k = preds[::-1][:k]\n",
    "        \n",
    "    recommended_k = (top_k >= rec_threshold).sum()\n",
    "    relevant_k = ((top_k >= rec_threshold) * (real >= rec_threshold)[:k]).sum()\n",
    "    \n",
    "    return 1 if recommended_k == 0 else relevant_k / recommended_k\n",
    "\n",
    "\n",
    "def hitrate_k(real: np.array, preds: np.array, rec_threshold=0.5, k=5):\n",
    "    real = real[(-preds).argsort()]\n",
    "    preds.sort()\n",
    "    \n",
    "    top_k = preds[::-1][:k]\n",
    "        \n",
    "    relevant_total = (real >= rec_threshold).sum()\n",
    "    relevant_k = ((top_k >= rec_threshold) * (real >= rec_threshold)[:k]).sum()\n",
    "    \n",
    "    return 1 if relevant_total == 0 else relevant_k / relevant_total  \n",
    "\n",
    "\n",
    "def f1_k(real: np.array, preds: np.array, b:float=1, rec_threshold=0.5, k=5):\n",
    "    real = real[(-preds).argsort()]\n",
    "    preds.sort()\n",
    "    \n",
    "    top_k = preds[::-1][:k]\n",
    "\n",
    "    relevant_k = ((top_k >= rec_threshold) * (real >= rec_threshold)[:k]).sum()\n",
    "    recommended_k = (top_k >= rec_threshold).sum()\n",
    "    relevant_total = (real >= rec_threshold).sum()\n",
    "    \n",
    "    precision = relevant_k / recommended_k if recommended_k != 0 else 1\n",
    "    recall = relevant_k / relevant_total if relevant_total != 0 else 1\n",
    "    \n",
    "    return (1 + b**2) * precision * recall / (b**2 * precision + recall)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2d2ec3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P@k = \t 0.6666666666666666\n",
      "Hitrate@k = \t 0.6666666666666666\n",
      "F1@k = \t 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "real, preds = np.array([4, 2, 3, 5, 2, 4]), np.array([2.3, 3.6, 3.4, 4.5, 4.9, 4.3])\n",
    "\n",
    "print(f'P@k = \\t {precision_k(real, preds, rec_threshold=3.5, k=3)}') # 0.67 precision\n",
    "print(f'Hitrate@k = \\t {hitrate_k(real, preds, rec_threshold=3.5, k=3)}') # 0.67 hitrate / recall\n",
    "print(f'F1@k = \\t {f1_k(real, preds, rec_threshold=3.5, k=3)}') # 0.67 f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc27028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP@k = \t 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# TODO: fix\n",
    "def average_precision(real: np.array, preds: np.array, rec_threshold=0.5):\n",
    "    real = real[(-preds).argsort()]\n",
    "    preds.sort()\n",
    "    preds = preds[::-1]\n",
    "            \n",
    "    relevant_total = (real >= rec_threshold).sum()\n",
    "    \n",
    "    def rel(k):\n",
    "        return int(preds[k] >= rec_threshold and real[k] >= rec_threshold)\n",
    "    \n",
    "    ap = 0\n",
    "    \n",
    "    for k in range(preds.size):\n",
    "        ap += precision_k(real, preds, rec_threshold, k) * rel(k)\n",
    "    \n",
    "    return ap / relevant_total\n",
    "\n",
    "real, preds = np.array([4, 2, 3, 5, 2, 4]), np.array([2.3, 3.6, 3.4, 4.5, 4.9, 4.3])\n",
    "\n",
    "print(f'AP@k = \\t {average_precision(real, preds, rec_threshold=3.5)}') # 0.5 average precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2dc5e6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "y_true = np.array([0, 0, 1, 1])\n",
    "y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "\n",
    "average_precision(y_true, y_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
